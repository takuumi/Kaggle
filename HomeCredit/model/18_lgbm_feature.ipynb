{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/shivamb/homecreditrisk-extensive-eda-baseline-0-772"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from wordcloud import WordCloud\n",
    "import plotly.graph_objs as go\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "from plotly import tools\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import random \n",
    "from sklearn.metrics import log_loss, roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold, ParameterGrid\n",
    "from  tqdm import tqdm\n",
    "import gc\n",
    "from functools import partial\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "path = \"../input/\"\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 2000)\n",
    "\n",
    "import time\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def timer(title):\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('read application_train.csv'):\n",
    "    app_train = pd.read_csv(path + \"application_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('read bureau.csv'):\n",
    "    bureau = pd.read_csv(path + \"bureau.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('read bureau_balance.csv'):\n",
    "    bureau_balance = pd.read_csv(path + \"bureau_balance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_balance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('read credit_card_balance.csv'):\n",
    "    credit_card_balance = pd.read_csv(path + \"credit_card_balance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_balance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('read POS_CASH_balance.csv'):\n",
    "    pcb = pd.read_csv(path + \"POS_CASH_balance.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('read previous_application.csv'):\n",
    "    previous_application = pd.read_csv(path + \"previous_application.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_application.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('read installments_payments.csv'):\n",
    "    installments_payments = pd.read_csv(path + \"installments_payments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "installments_payments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データ準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "with timer('read application_test.csv'):\n",
    "    app_test = pd.read_csv('../input/application_test.csv')\n",
    "\n",
    "\n",
    "with timer('perapare'):\n",
    "    app_test['is_test'] = 1 \n",
    "    app_test['is_train'] = 0\n",
    "    app_train['is_test'] = 0\n",
    "    app_train['is_train'] = 1\n",
    "\n",
    "    # target variable\n",
    "    Y = app_train['TARGET']\n",
    "    train_X = app_train.drop(['TARGET'], axis = 1)\n",
    "\n",
    "    # test ID\n",
    "    test_id = app_test['SK_ID_CURR']\n",
    "    test_X = app_test\n",
    "\n",
    "    # merge train and test datasets for preprocessing\n",
    "    data = pd.concat([train_X, test_X], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"0.1\">0.1 Prepare - Data Cleaning</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with timer('app remove meaningless feature'):\n",
    "    data.drop(['FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', \n",
    "            'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', \n",
    "            'FLAG_DOCUMENT_21'], axis = 1, inplace = True)\n",
    "\n",
    "with timer('replace outliers'):\n",
    "    data['DAYS_EMPLOYED'].replace(365243, np.nan, inplace = True)\n",
    "    data['CODE_GENDER'].replace('XNA', np.nan, inplace=True)\n",
    "    data['NAME_FAMILY_STATUS'].replace('Unknown', np.nan, inplace=True)\n",
    "    data['ORGANIZATION_TYPE'].replace('XNA', np.nan, inplace=True)\n",
    "    data['DAYS_LAST_PHONE_CHANGE'].replace(0, np.nan, inplace=True)\n",
    "\n",
    "    data.loc[data['OWN_CAR_AGE'] > 80, 'OWN_CAR_AGE'] = np.nan\n",
    "    data.loc[data['REGION_RATING_CLIENT_W_CITY'] < 0, 'REGION_RATING_CLIENT_W_CITY'] = np.nan\n",
    "    data.loc[data['AMT_INCOME_TOTAL'] > 1e8, 'AMT_INCOME_TOTAL'] = np.nan\n",
    "    data.loc[data['AMT_REQ_CREDIT_BUREAU_QRT'] > 10, 'AMT_REQ_CREDIT_BUREAU_QRT'] = np.nan\n",
    "    data.loc[data['OBS_30_CNT_SOCIAL_CIRCLE'] > 40, 'OBS_30_CNT_SOCIAL_CIRCLE'] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('bureau replace outliers'):\n",
    "    bureau['AMT_CREDIT_SUM'].fillna(0, inplace=True)\n",
    "    bureau['AMT_CREDIT_SUM_DEBT'].fillna(0, inplace=True)\n",
    "    bureau['AMT_CREDIT_SUM_OVERDUE'].fillna(0, inplace=True)\n",
    "    bureau['CNT_CREDIT_PROLONG'].fillna(0, inplace=True)\n",
    "\n",
    "    bureau['DAYS_CREDIT_ENDDATE'][bureau['DAYS_CREDIT_ENDDATE'] < -40000] = np.nan\n",
    "    bureau['DAYS_CREDIT_UPDATE'][bureau['DAYS_CREDIT_UPDATE'] < -40000] = np.nan\n",
    "    bureau['DAYS_ENDDATE_FACT'][bureau['DAYS_ENDDATE_FACT'] < -40000] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('previous_application replace outliers'):\n",
    "    previous_application['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace=True)\n",
    "    previous_application['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace=True)\n",
    "    previous_application['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace=True)\n",
    "    previous_application['DAYS_LAST_DUE'].replace(365243, np.nan, inplace=True)\n",
    "    previous_application['DAYS_TERMINATION'].replace(365243, np.nan, inplace=True)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('credit_card_balance replace outliers'):\n",
    "    credit_card_balance['AMT_DRAWINGS_ATM_CURRENT'][credit_card_balance['AMT_DRAWINGS_ATM_CURRENT'] < 0] = np.nan\n",
    "    credit_card_balance['AMT_DRAWINGS_CURRENT'][credit_card_balance['AMT_DRAWINGS_CURRENT'] < 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('app features1'):\n",
    "    \n",
    "    data['app NAN num'] = data.isnull().sum(axis = 1).values        \n",
    "\n",
    "    data['app CNT_FAM_MEMBERS - CNT_CHILDREN'] = data['CNT_FAM_MEMBERS'] - data['CNT_CHILDREN']        \n",
    "    \n",
    "    data['app AMT_CREDIT / AMT_ANNUITY'] = data['AMT_CREDIT'] / data['AMT_ANNUITY']\n",
    "    data['app AMT_CREDIT / AMT_ANNUITY / DAYS_EMPLOYED'] = data['app AMT_CREDIT / AMT_ANNUITY'] / data['DAYS_EMPLOYED']\n",
    "    data['app AMT_CREDIT / AMT_INCOME_TOTAL'] = data['AMT_CREDIT'] / data['AMT_INCOME_TOTAL']\n",
    "    data['app AMT_CREDIT - AMT_GOODS_PRICE'] = data['AMT_CREDIT'] - data['AMT_GOODS_PRICE']\n",
    "    data['app AMT_CREDIT / AMT_GOODS_PRICE'] = data['AMT_CREDIT'] / data['AMT_GOODS_PRICE']\n",
    "    data['app AMT_CREDIT / CNT_FAM_MEMBERS'] = data['AMT_CREDIT'] / data['CNT_FAM_MEMBERS']\n",
    "    data['app AMT_CREDIT / (1 + CNT_CHILDREN)'] = data['AMT_CREDIT'] / (1 + data['CNT_CHILDREN'])\n",
    "    data['app AMT_CREDIT / (CNT_FAM_MEMBERS - CNT_CHILDREN)'] = data['AMT_CREDIT'] / data['app CNT_FAM_MEMBERS - CNT_CHILDREN']   \n",
    "    \n",
    "    data['app AMT_ANNUITY / AMT_INCOME_TOTAL'] = data['AMT_ANNUITY'] / data['AMT_INCOME_TOTAL']\n",
    "    data['app AMT_ANNUITY / AMT_CREDIT'] = data['AMT_ANNUITY'] / data['AMT_CREDIT']\n",
    "    \n",
    "    data['app AMT_INCOME_TOTAL / 12 - AMT_ANNUITY'] = data['AMT_INCOME_TOTAL'] / 12. - data['AMT_ANNUITY']\n",
    "    data['app AMT_INCOME_TOTAL / AMT_ANNUITY'] = data['AMT_INCOME_TOTAL'] / data['AMT_ANNUITY']\n",
    "    data['app AMT_INCOME_TOTAL - AMT_GOODS_PRICE'] = data['AMT_INCOME_TOTAL'] - data['AMT_GOODS_PRICE']\n",
    "    data['app AMT_INCOME_TOTAL / CNT_FAM_MEMBERS'] = data['AMT_INCOME_TOTAL'] / data['CNT_FAM_MEMBERS']\n",
    "    data['app AMT_INCOME_TOTAL / CNT_CHILDREN'] = data['AMT_INCOME_TOTAL'] / (1 + data['CNT_CHILDREN'])       \n",
    "    data['app AMT_INCOME_TOTAL / AMT_CREDIT'] = data['AMT_INCOME_TOTAL'] / data['AMT_CREDIT']\n",
    "    data['app AMT_INCOME_TOTAL / (CNT_FAM_MEMBERS - CNT_CHILDREN) '] = data['AMT_INCOME_TOTAL'] / data['app CNT_FAM_MEMBERS - CNT_CHILDREN']\n",
    "    \n",
    "    data['app DAYS_EMPLOYED / DAYS_BIRTH'] = data['DAYS_EMPLOYED'] / data['DAYS_BIRTH']\n",
    "\n",
    "    data['app EXT_SOURCE mean'] = data[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].mean(axis = 1)\n",
    "    data['app EXT_SOURCE std'] = data[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']].std(axis = 1)\n",
    "    data['app EXT_SOURCE prod'] = data['EXT_SOURCE_1'] * data['EXT_SOURCE_2'] * data['EXT_SOURCE_3']\n",
    "    data['app EXT_SOURCE_1 * DAYS_EMPLOYED'] = data['EXT_SOURCE_1'] * data['DAYS_EMPLOYED']\n",
    "    data['app EXT_SOURCE_2 * DAYS_EMPLOYED'] = data['EXT_SOURCE_2'] * data['DAYS_EMPLOYED']\n",
    "    data['app EXT_SOURCE_3 * DAYS_EMPLOYED'] = data['EXT_SOURCE_3'] * data['DAYS_EMPLOYED']\n",
    "    data['app EXT_SOURCE_1 / DAYS_BIRTH'] = data['EXT_SOURCE_1'] / data['DAYS_BIRTH']\n",
    "    data['app EXT_SOURCE_2 / DAYS_BIRTH'] = data['EXT_SOURCE_2'] / data['DAYS_BIRTH']\n",
    "    data['app EXT_SOURCE_3 / DAYS_BIRTH'] = data['EXT_SOURCE_3'] / data['DAYS_BIRTH']\n",
    "\n",
    "    data['app OWN_CAR_AGE / DAYS_BIRTH'] = data['OWN_CAR_AGE'] / data['DAYS_BIRTH']\n",
    "    data['app OWN_CAR_AGE / DAYS_EMPLOYED'] = data['OWN_CAR_AGE'] / data['DAYS_EMPLOYED']\n",
    "\n",
    "    data['app DAYS_LAST_PHONE_CHANGE / DAYS_BIRTH'] = data['DAYS_LAST_PHONE_CHANGE'] / data['DAYS_BIRTH']\n",
    "    data['app DAYS_LAST_PHONE_CHANGE / DAYS_EMPLOYED'] = data['DAYS_LAST_PHONE_CHANGE'] / data['DAYS_EMPLOYED']\n",
    "\n",
    "    data['app DAYS_EMPLOYED - DAYS_BIRTH'] = data['DAYS_EMPLOYED'] - data['DAYS_BIRTH']\n",
    "    data['app DAYS_EMPLOYED / DAYS_BIRTH'] = data['DAYS_EMPLOYED'] / data['DAYS_BIRTH']\n",
    "    data['app DAYS_EMPLOYED - DAYS_REGISTRATION'] = data['DAYS_EMPLOYED'] - data['DAYS_REGISTRATION']\n",
    "    data['app DAYS_EMPLOYED - DAYS_ID_PUBLISH'] = data['DAYS_EMPLOYED'] - data['DAYS_ID_PUBLISH']\n",
    "    \n",
    "    data['app CNT_CHILDREN / CNT_FAM_MEMBERS'] = data['CNT_CHILDREN'] / data['CNT_FAM_MEMBERS']\n",
    "    data['app CNT_CHILDREN / CNT_CHILDREN'] = data['CNT_CHILDREN'] / data['CNT_FAM_MEMBERS']\n",
    "    data['app CNT_CHILDREN / (CNT_FAM_MEMBERS - CNT_CHILDREN)'] = data['CNT_CHILDREN'] / data['app CNT_FAM_MEMBERS - CNT_CHILDREN']\n",
    "    \n",
    "    data['app OBS_30_CNT_SOCIAL_CIRCLE - DEF_30_CNT_SOCIAL_CIRCLE'] = data['OBS_30_CNT_SOCIAL_CIRCLE'] - data['DEF_30_CNT_SOCIAL_CIRCLE']\n",
    "    data['app OBS_60_CNT_SOCIAL_CIRCLE - DEF_60_CNT_SOCIAL_CIRCLE'] = data['OBS_60_CNT_SOCIAL_CIRCLE'] - data['DEF_60_CNT_SOCIAL_CIRCLE']\n",
    "    \n",
    "with timer('app features2'):\n",
    "    data['app most popular AMT_GOODS_PRICE'] = data['AMT_GOODS_PRICE'] \\\n",
    "                            .isin([225000, 450000, 675000, 900000]).map({True: 1, False: 0})\n",
    "    data['app popular AMT_GOODS_PRICE'] = data['AMT_GOODS_PRICE'] \\\n",
    "                            .isin([1125000, 1350000, 1575000, 1800000, 2250000]).map({True: 1, False: 0})\n",
    "    data['app TOTAL_DOCS_SUBMITTED'] = data.loc[:, data.columns.str.contains('FLAG_DOCUMENT')].sum(axis=1)\n",
    "    data['app DAYS_EMPLOYED < -2000'] = (data['DAYS_EMPLOYED'] < -2000).astype(int)\n",
    "    data['DAYS_BIRTH < -14000'] = (data['DAYS_BIRTH'] < -14000).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('app features handcraft definition'):\n",
    "    data['app self cate OCCUPATION_TYPE'] = data['OCCUPATION_TYPE'].replace(\n",
    "                       {'High skill tech staff':0,\n",
    "                        'Managers':0,\n",
    "                        'Accountants':0,\n",
    "                        'HR staff':0,\n",
    "                        'Core staff':0,\n",
    "                       'Cooking staff':1,\n",
    "                        'Realty agents':0,\n",
    "                        'Sales staff':1,\n",
    "                        'IT staff':0,\n",
    "                        'Medicine staff':0,\n",
    "                        'Secretaries':0,\n",
    "                        'Security staff':1,\n",
    "                        'Cleaning staff':1,\n",
    "                          'Laborers':1,\n",
    "                          'Low-skill Laborers':1,\n",
    "                          'Cleaning staff':1,\n",
    "                        'Waiters/barmen staff':1,\n",
    "                        'Private service staff':0,\n",
    "                        'Drivers':1,\n",
    "                        'High skill tech staff':0                                                                       \n",
    "                        },inplace=False)\n",
    "\n",
    "    data['app self cate NAME_INCOME_TYPE'] = data['NAME_INCOME_TYPE'].replace(\n",
    "                        {'Businessman':0,\n",
    "                         'Student':0,\n",
    "                         'Unemployed':1,\n",
    "                         'Working':1,\n",
    "                         'Commercial associate':0,                        \n",
    "                         'State servant':0,\n",
    "                         'Pensioner':0,                         \n",
    "                         'Maternity leave':1}\n",
    "                        ,inplace=False)\n",
    "\n",
    "    data['app self cate NAME_HOUSING_TYPE'] = data['NAME_HOUSING_TYPE'].replace(\n",
    "                        {'Rented apartment':1,\n",
    "                         'With parents':1,\n",
    "                         'Municipal apartment':0,\n",
    "                         'Co-op apartment':0,\n",
    "                         'House / apartment':0,                        \n",
    "                         'Office apartment':0}\n",
    "                        ,inplace=False)\n",
    "\n",
    "    data['app self cate ORGANIZATION_TYPE'] = data['ORGANIZATION_TYPE'].replace(\n",
    "                        {'Transport':1, \n",
    "                        'Industry: type 13':1, \n",
    "                        'Industry: type 8':1, \n",
    "                        'Transport: type 3':1,\n",
    "                        'Restaurant':1, \n",
    "                        'Construction':1,\n",
    "                        'Cleaning':1,\n",
    "                        'Industry: type 1':1,\n",
    "                        'Industry: type 3':1,\n",
    "                        'Realtor':1,\n",
    "                        'Agriculture':1,\n",
    "                        'Trade: type 3':1,\n",
    "                        'Self-employed':1,\n",
    "                        'Industry: type 4':1,\n",
    "                        'Security':0,\n",
    "                        'Trade: type 7':0,\n",
    "                        'Business Entity Type 3':0,\n",
    "                        'Transport: type 4':0,\n",
    "                        'Mobile':0,\n",
    "                        'Trade: type 1':0,\n",
    "                        'Industry: type 11':0,\n",
    "                        'Business Entity Type 2':0,\n",
    "                        'Postal':0,\n",
    "                        'Advertising':0,\n",
    "                        'Business Entity Type 1':0,\n",
    "                        'Industry: type 7':0,\n",
    "                        'Housing':0,\n",
    "                        'Legal Services':0,\n",
    "                        'Transport: type 2':0,\n",
    "                        'Other':0,\n",
    "                        'Telecom':0,\n",
    "                        'Industry: type 2':0,\n",
    "                        'Industry: type 6':0,\n",
    "                        'Emergency':0,\n",
    "                        'Kindergarten':0,\n",
    "                        'Trade: type 2':0,\n",
    "                        'Government':0,\n",
    "                        'Industry: type 5':0,\n",
    "                        'Industry: type 9':0,\n",
    "                        'Electricity':0,\n",
    "                        'Services':0,\n",
    "                        'Medicine':0,\n",
    "                        'Industry: type 10':0,\n",
    "                        'Hotel':0,\n",
    "                        'Trade: type 5':0,\n",
    "                        'School':0,\n",
    "                        'Religion':0,\n",
    "                        'Insurance':0,\n",
    "                        'Culture':0,\n",
    "                        'XNA':0,\n",
    "                        'Bank':0,\n",
    "                        'Military':0,\n",
    "                        'Police':0,\n",
    "                        'University':0,\n",
    "                        'Security Ministries':0,\n",
    "                        'Trade: type 6':0,\n",
    "                        'Transport: type 1':0,\n",
    "                        'Industry: type 12':0,\n",
    "                        'Trade: type 4':0}\n",
    "                        ,inplace=False)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('app features handcraft'):\n",
    "    ### 勝手にデータ定義して作ってみたものの、事実に基づいてないからダメかもしれない。あんまり足すのはやめておこう。\n",
    "    # app self cate OCCUPATION_TYPE\n",
    "    data['app self cate occ AMT_CREDIT / AMT_INCOME_TOTAL'] = data['app self cate OCCUPATION_TYPE'] * data['AMT_CREDIT'] / data['AMT_INCOME_TOTAL']\n",
    "    data['app self cate occ AMT_ANNUITY / AMT_INCOME_TOTAL'] = data['app self cate OCCUPATION_TYPE'] * data['AMT_ANNUITY'] / data['AMT_INCOME_TOTAL']\n",
    "    data['app self cate occ AMT_CREDIT / AMT_ANNUITY'] = data['app self cate OCCUPATION_TYPE'] * data['AMT_CREDIT'] / data['AMT_ANNUITY']\n",
    "    data['app self cate occ DAYS_EMPLOYED / DAYS_BIRTH'] = data['app self cate OCCUPATION_TYPE'] * data['DAYS_EMPLOYED'] / data['DAYS_BIRTH']\n",
    "\n",
    "    # app self cate NAME_INCOME_TYPE\n",
    "    data['app self cate income AMT_CREDIT / AMT_INCOME_TOTAL'] = data['app self cate NAME_INCOME_TYPE'] * data['AMT_CREDIT'] / data['AMT_INCOME_TOTAL']\n",
    "    data['app self cate income AMT_ANNUITY / AMT_INCOME_TOTAL'] = data['app self cate NAME_INCOME_TYPE'] * data['AMT_ANNUITY'] / data['AMT_INCOME_TOTAL']\n",
    "    data['app self cate income AMT_CREDIT / AMT_ANNUITY'] = data['app self cate NAME_INCOME_TYPE'] * data['AMT_CREDIT'] / data['AMT_ANNUITY']\n",
    "    data['app self cate income DAYS_EMPLOYED / DAYS_BIRTH'] = data['app self cate NAME_INCOME_TYPE'] * data['DAYS_EMPLOYED'] / data['DAYS_BIRTH']\n",
    "\n",
    "    # app self cate NAME_HOUSING_TYPE\n",
    "    data['app self cate housing AMT_CREDIT / AMT_INCOME_TOTAL'] = data['app self cate NAME_HOUSING_TYPE'] * data['AMT_CREDIT'] / data['AMT_INCOME_TOTAL']\n",
    "    data['app self cate housing AMT_ANNUITY / AMT_INCOME_TOTAL'] = data['app self cate NAME_HOUSING_TYPE'] * data['AMT_ANNUITY'] / data['AMT_INCOME_TOTAL']\n",
    "    data['app self cate housing AMT_CREDIT / AMT_ANNUITY'] = data['app self cate NAME_HOUSING_TYPE'] * data['AMT_CREDIT'] / data['AMT_ANNUITY']\n",
    "    data['app self cate housing DAYS_EMPLOYED / DAYS_BIRTH'] = data['app self cate NAME_HOUSING_TYPE'] * data['DAYS_EMPLOYED'] / data['DAYS_BIRTH']\n",
    "\n",
    "    # app self cate ORGANIZATION_TYPE\n",
    "    data['app self cate org AMT_CREDIT / AMT_INCOME_TOTAL'] = data['app self cate ORGANIZATION_TYPE'] * data['AMT_CREDIT'] / data['AMT_INCOME_TOTAL']\n",
    "    data['app self cate org AMT_ANNUITY / AMT_INCOME_TOTAL'] = data['app self cate ORGANIZATION_TYPE'] * data['AMT_ANNUITY'] / data['AMT_INCOME_TOTAL']\n",
    "    data['app self cate org AMT_CREDIT / AMT_ANNUITY'] = data['app self cate ORGANIZATION_TYPE'] * data['AMT_CREDIT'] / data['AMT_ANNUITY']\n",
    "    data['app self cate org DAYS_EMPLOYED / DAYS_BIRTH'] = data['app self cate ORGANIZATION_TYPE'] * data['DAYS_EMPLOYED'] / data['DAYS_BIRTH']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('app groupby features define'):\n",
    "    APP_AGGREGATION_RECIPIES = [\n",
    "        (['CODE_GENDER', 'NAME_EDUCATION_TYPE'], [('AMT_ANNUITY', 'max'),\n",
    "                                                  ('AMT_CREDIT', 'max'),\n",
    "                                                  ('EXT_SOURCE_1', 'mean'),\n",
    "                                                  ('EXT_SOURCE_2', 'mean'),\n",
    "                                                  ('OWN_CAR_AGE', 'max'),\n",
    "                                                  ('OWN_CAR_AGE', 'sum')]),\n",
    "        (['CODE_GENDER', 'ORGANIZATION_TYPE'], [('AMT_ANNUITY', 'mean'),\n",
    "                                                ('AMT_INCOME_TOTAL', 'mean'),\n",
    "                                                ('DAYS_REGISTRATION', 'mean'),\n",
    "                                                ('EXT_SOURCE_1', 'mean')]),\n",
    "        (['CODE_GENDER', 'REG_CITY_NOT_WORK_CITY'], [('AMT_ANNUITY', 'mean'),\n",
    "                                                     ('CNT_CHILDREN', 'mean'),\n",
    "                                                     ('DAYS_ID_PUBLISH', 'mean')]),\n",
    "        (['CODE_GENDER', 'NAME_EDUCATION_TYPE', 'OCCUPATION_TYPE', 'REG_CITY_NOT_WORK_CITY'], [('EXT_SOURCE_1', 'mean'),\n",
    "                                                                                               ('EXT_SOURCE_2', 'mean')]),\n",
    "        (['NAME_EDUCATION_TYPE', 'OCCUPATION_TYPE'], [('AMT_CREDIT', 'mean'),\n",
    "                                                      ('AMT_REQ_CREDIT_BUREAU_YEAR', 'mean'),\n",
    "                                                      ('APARTMENTS_AVG', 'mean'),\n",
    "                                                      ('BASEMENTAREA_AVG', 'mean'),\n",
    "                                                      ('EXT_SOURCE_1', 'mean'),\n",
    "                                                      ('EXT_SOURCE_2', 'mean'),\n",
    "                                                      ('EXT_SOURCE_3', 'mean'),\n",
    "                                                      ('NONLIVINGAREA_AVG', 'mean'),\n",
    "                                                      ('OWN_CAR_AGE', 'mean'),\n",
    "                                                      ('YEARS_BUILD_AVG', 'mean')]),\n",
    "        (['NAME_EDUCATION_TYPE', 'OCCUPATION_TYPE', 'REG_CITY_NOT_WORK_CITY'], [('ELEVATORS_AVG', 'mean'),\n",
    "                                                                                ('EXT_SOURCE_1', 'mean')]),\n",
    "        (['OCCUPATION_TYPE'], [('AMT_ANNUITY', 'mean'),\n",
    "                               ('CNT_CHILDREN', 'mean'),\n",
    "                               ('CNT_FAM_MEMBERS', 'mean'),\n",
    "                               ('DAYS_BIRTH', 'mean'),\n",
    "                               ('DAYS_EMPLOYED', 'mean'),\n",
    "                               ('DAYS_ID_PUBLISH', 'mean'),\n",
    "                               ('DAYS_REGISTRATION', 'mean'),\n",
    "                               ('EXT_SOURCE_1', 'mean'),\n",
    "                               ('EXT_SOURCE_2', 'mean'),\n",
    "                               ('EXT_SOURCE_3', 'mean')]),\n",
    "        (['NAME_CONTRACT_TYPE'], [('app AMT_CREDIT / AMT_ANNUITY', 'mean'),\n",
    "                                  ('app EXT_SOURCE mean', 'max'),\n",
    "                                  ('app DAYS_EMPLOYED / DAYS_BIRTH', 'mean')]),\n",
    "        (['REGION_RATING_CLIENT', 'NAME_HOUSING_TYPE'], [('AMT_CREDIT', 'mean'),\n",
    "                                                      ('AMT_REQ_CREDIT_BUREAU_YEAR', 'mean'),\n",
    "                                                      ('APARTMENTS_AVG', 'mean'),\n",
    "                                                      ('BASEMENTAREA_AVG', 'mean'),\n",
    "                                                      ('EXT_SOURCE_1', 'mean'),\n",
    "                                                      ('EXT_SOURCE_2', 'mean'),\n",
    "                                                      ('EXT_SOURCE_3', 'mean'),\n",
    "                                                      ('NONLIVINGAREA_AVG', 'mean'),\n",
    "                                                      ('OWN_CAR_AGE', 'mean'),\n",
    "                                                      ('YEARS_BUILD_AVG', 'mean')]),\n",
    "        (['CODE_GENDER', 'NAME_INCOME_TYPE'], [('AMT_ANNUITY', 'mean'),\n",
    "                                                ('app AMT_CREDIT / AMT_ANNUITY', 'mean'),\n",
    "                                                ('DAYS_REGISTRATION', 'mean'),\n",
    "                                                ('OWN_CAR_AGE', 'mean'),                                               \n",
    "                                                ('EXT_SOURCE_1', 'mean')]), \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_agg_by_recipies(targetData, RECIPES, prefix):\n",
    "    groupby_aggregate_names = []\n",
    "    for groupby_cols, specs in tqdm(RECIPES):\n",
    "        group_object = targetData.groupby(groupby_cols)\n",
    "        for select, agg in tqdm(specs):\n",
    "            groupby_aggregate_name = '{}_{}_{}_{}'.format(prefix, '_'.join(groupby_cols), agg, select)\n",
    "            targetData = targetData.merge(group_object[select]\n",
    "                                  .agg(agg)\n",
    "                                  .reset_index()\n",
    "                                  .rename(index=str,\n",
    "                                          columns={select: groupby_aggregate_name})\n",
    "                                  [groupby_cols + [groupby_aggregate_name]],\n",
    "                                  on=groupby_cols,\n",
    "                                  how='left')\n",
    "            groupby_aggregate_names.append(groupby_aggregate_name)\n",
    "    return targetData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_agg_diff_by_recipies(targetData, RECIPES, prefix):\n",
    "    groupby_aggregate_names = []\n",
    "    for groupby_cols, specs in tqdm(RECIPES):\n",
    "        group_object = targetData.groupby(groupby_cols)\n",
    "        for select, agg in tqdm(specs):\n",
    "            groupby_aggregate_name = '{}_{}_{}_{}'.format(prefix, '_'.join(groupby_cols), agg, select)\n",
    "            targetData = targetData.merge(group_object[select]\n",
    "                                  .agg(agg)\n",
    "                                  .reset_index()\n",
    "                                  .rename(index=str,\n",
    "                                          columns={select: groupby_aggregate_name})\n",
    "                                  [groupby_cols + [groupby_aggregate_name]],\n",
    "                                  on=groupby_cols,\n",
    "                                  how='left')\n",
    "            groupby_aggregate_names.append(groupby_aggregate_name)\n",
    "    return targetData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('app groupby features'):\n",
    "    data  = make_agg_by_recipies(data, APP_AGGREGATION_RECIPIES, 'app ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('app groupby features diff'):\n",
    "    data  = make_agg_diff_by_recipies(data, APP_AGGREGATION_RECIPIES, 'app ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('categorical data processing function'):\n",
    "    # function to obtain Categorical Features\n",
    "    def _get_categorical_features(df):\n",
    "        feats = [col for col in list(df.columns) if df[col].dtype == 'object']\n",
    "        return feats\n",
    "\n",
    "    # function to factorize categorical features\n",
    "    def _factorize_categoricals(df, cats):\n",
    "        for col in cats:\n",
    "            df[col], _ = pd.factorize(df[col])\n",
    "        return df \n",
    "\n",
    "    # function to create dummy variables of categorical features\n",
    "    def _get_dummies(df, cats):\n",
    "        for col in cats:\n",
    "            df = pd.concat([df, pd.get_dummies(df[col], prefix=col)], axis=1)\n",
    "        return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('categorical data processing'):\n",
    "    # get categorical features\n",
    "    data_cats = _get_categorical_features(data)\n",
    "    # factorize the categorical features from train and test data\n",
    "    data = _factorize_categoricals(data, data_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"1.1\">1.1 Feature Engineering - Previous Applications</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('previous_application merged'):   \n",
    "    pos_avg = pcb.drop(['SK_ID_CURR'], axis = 1).groupby('SK_ID_PREV').mean()\n",
    "    pos_avg.columns = ['pre_pcb ' + col + '_mean' for col in pos_avg.columns]\n",
    "    previous_application = previous_application.merge(right=pos_avg.reset_index(), how='left', on='SK_ID_PREV')\n",
    "    ins_avg = installments_payments.drop(['SK_ID_CURR'], axis = 1).groupby('SK_ID_PREV').mean()\n",
    "    ins_avg.columns = ['pre_ins ' + col + '_mean' for col in ins_avg.columns]\n",
    "    previous_application = previous_application.merge(right=ins_avg.reset_index(), how='left', on='SK_ID_PREV')\n",
    "    ccb_avg = credit_card_balance.drop(['SK_ID_CURR'], axis = 1).groupby('SK_ID_PREV').mean()\n",
    "    ccb_avg.columns = ['pre_ccb ' + col + '_mean' for col in ccb_avg.columns]\n",
    "    previous_application = previous_application.merge(right=ccb_avg.reset_index(), how='left', on='SK_ID_PREV')\n",
    "    del pos_avg, ins_avg, ccb_avg\n",
    "    gc.collect()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('previous_application features'):    \n",
    "    ## count the number of previous applications for a given ID\n",
    "    prev_apps_count = previous_application[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "    previous_application['pre SK_ID_PREV_CNT'] = previous_application['SK_ID_CURR'].map(prev_apps_count['SK_ID_PREV'])\n",
    "    previous_application.drop(['SK_ID_PREV'], axis = 1, inplace = True)\n",
    "\n",
    "    # nan num\n",
    "    previous_application['pre NAN num'] = previous_application.isnull().sum(axis = 1).values\n",
    "\n",
    "\n",
    "with timer('previous_application features'):\n",
    "    # feature\n",
    "    previous_application['pre AMT_APPLICATION / AMT_CREDIT'] = previous_application['AMT_APPLICATION'] / previous_application['AMT_CREDIT']\n",
    "    previous_application['pre AMT_CREDIT / AMT_ANNUITY'] = previous_application['AMT_CREDIT'] / previous_application['AMT_ANNUITY']\n",
    "    previous_application['pre AMT_CREDIT - AMT_GOODS_PRICE'] = previous_application['AMT_CREDIT'] - previous_application['AMT_GOODS_PRICE']        \n",
    "    previous_application['pre AMT_CREDIT / AMT_GOODS_PRICE'] = previous_application['AMT_CREDIT'] / previous_application['AMT_GOODS_PRICE']    \n",
    "    previous_application['pre AMT_ANNUITY / AMT_CREDIT'] = previous_application['AMT_CREDIT'] / previous_application['AMT_GOODS_PRICE']    \n",
    "\n",
    "    previous_application['pre DAYS_LAST_DUE_1ST_VERSION - DAYS_LAST_DUE'] = previous_application['DAYS_LAST_DUE_1ST_VERSION'] - previous_application['DAYS_LAST_DUE']\n",
    "    previous_application['pre DAYS_LAST_DUE - DAYS_TERMINATION'] = previous_application['DAYS_LAST_DUE'] - previous_application['DAYS_TERMINATION']\n",
    "    \n",
    "    previous_application['pre AMT_GOODS_PRICE / CNT_PAYMENT'] = previous_application['AMT_GOODS_PRICE'] / previous_application['CNT_PAYMENT']    \n",
    "    \n",
    "    \n",
    "    \n",
    "with timer('merged data features'):\n",
    "    previous_application['mer pre_pcb MONTHS_BALANCE_mean - pre_ccb MONTHS_BALANCE_mean'] = previous_application['pre_pcb MONTHS_BALANCE_mean'] - previous_application['pre_ccb MONTHS_BALANCE_mean']\n",
    "\n",
    "    previous_application['mer DAYS_FIRST_DUE - pre_ins DAYS_INSTALMENT_mean'] = previous_application['DAYS_FIRST_DUE'] - previous_application['pre_ins DAYS_INSTALMENT_mean']\n",
    "    previous_application['mer DAYS_FIRST_DUE - pre_ins DAYS_ENTRY_PAYMENT_mean'] = previous_application['DAYS_FIRST_DUE'] - previous_application['pre_ins DAYS_ENTRY_PAYMENT_mean']    \n",
    "    previous_application['mer DAYS_LAST_DUE - pre_ins DAYS_INSTALMENT_mean'] = previous_application['DAYS_LAST_DUE'] - previous_application['pre_ins DAYS_INSTALMENT_mean']\n",
    "    previous_application['mer DAYS_LAST_DUE - pre_ins DAYS_ENTRY_PAYMENT_mean'] = previous_application['DAYS_LAST_DUE'] - previous_application['pre_ins DAYS_ENTRY_PAYMENT_mean']    \n",
    "    previous_application['mer DAYS_LAST_DUE_1ST_VERSION - pre_ins DAYS_INSTALMENT_mean'] = previous_application['DAYS_LAST_DUE_1ST_VERSION'] - previous_application['pre_ins DAYS_INSTALMENT_mean']\n",
    "    previous_application['mer DAYS_LAST_DUE_1ST_VERSION - pre_ins DAYS_ENTRY_PAYMENT_mean'] = previous_application['DAYS_LAST_DUE_1ST_VERSION'] - previous_application['pre_ins DAYS_ENTRY_PAYMENT_mean']    \n",
    "\n",
    "    previous_application['mer AMT_APPLICATION / pre_ins AMT_INSTALMENT_mean'] = previous_application['AMT_APPLICATION'] / previous_application['pre_ins AMT_INSTALMENT_mean']\n",
    "    previous_application['mer AMT_APPLICATION / pre_ins AMT_PAYMENT_mean'] = previous_application['AMT_APPLICATION'] / previous_application['pre_ins AMT_PAYMENT_mean']\n",
    "    previous_application['mer AMT_CREDIT / pre_ins AMT_INSTALMENT_mean'] = previous_application['AMT_CREDIT'] / previous_application['pre_ins AMT_INSTALMENT_mean']\n",
    "    previous_application['mer AMT_CREDIT / pre_ins AMT_PAYMENT_mean'] = previous_application['AMT_CREDIT'] / previous_application['pre_ins AMT_PAYMENT_mean']\n",
    "    previous_application['mer AMT_GOODS_PRICE / pre_ins AMT_INSTALMENT_mean'] = previous_application['AMT_GOODS_PRICE'] / previous_application['pre_ins AMT_INSTALMENT_mean']\n",
    "    previous_application['mer AMT_GOODS_PRICE / pre_ins AMT_PAYMENT_mean'] = previous_application['AMT_GOODS_PRICE'] / previous_application['pre_ins AMT_PAYMENT_mean']\n",
    "\n",
    "    previous_application['mer CNT_PAYMENT / pre_pcb CNT_INSTALMENT_mean'] = previous_application['CNT_PAYMENT'] / previous_application['pre_pcb CNT_INSTALMENT_mean']\n",
    "    previous_application['mer CNT_PAYMENT / pre_pcb CNT_INSTALMENT_FUTURE_mean'] = previous_application['CNT_PAYMENT'] / previous_application['pre_pcb CNT_INSTALMENT_FUTURE_mean']\n",
    "    previous_application['mer CNT_PAYMENT / pre_ccb CNT_DRAWINGS_ATM_CURRENT_mean'] = previous_application['CNT_PAYMENT'] / previous_application['pre_ccb CNT_DRAWINGS_ATM_CURRENT_mean']\n",
    "    previous_application['mer CNT_PAYMENT / pre_ccb CNT_INSTALMENT_MATURE_CUM_mean'] = previous_application['CNT_PAYMENT'] / previous_application['pre_ccb CNT_INSTALMENT_MATURE_CUM_mean']\n",
    "\n",
    "    previous_application['mer pre_ccb CNT_DRAWINGS_ATM_CURRENT_mean / pre_pcb CNT_INSTALMENT_mean'] = previous_application['pre_ccb CNT_DRAWINGS_ATM_CURRENT_mean'] / previous_application['pre_pcb CNT_INSTALMENT_mean']\n",
    "    previous_application['mer pre_ccb CNT_DRAWINGS_ATM_CURRENT_mean / pre_pcb CNT_INSTALMENT_FUTURE_mean'] = previous_application['pre_ccb CNT_DRAWINGS_ATM_CURRENT_mean'] / previous_application['pre_pcb CNT_INSTALMENT_FUTURE_mean']\n",
    "    previous_application['mer pre_ccb CNT_INSTALMENT_MATURE_CUM_mean / pre_pcb CNT_INSTALMENT_mean'] = previous_application['pre_ccb CNT_INSTALMENT_MATURE_CUM_mean'] / previous_application['pre_pcb CNT_INSTALMENT_mean']\n",
    "    previous_application['mer pre_ccb CNT_INSTALMENT_MATURE_CUM_mean / pre_pcb CNT_INSTALMENT_FUTURE_mean'] = previous_application['pre_ccb CNT_INSTALMENT_MATURE_CUM_mean'] / previous_application['pre_pcb CNT_INSTALMENT_FUTURE_mean']\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('previous_application groupby features define'):\n",
    "    PRE_AGGREGATION_RECIPIES = [\n",
    "        (['NAME_CONTRACT_TYPE'], [('pre AMT_CREDIT / AMT_ANNUITY', 'mean'),\n",
    "                                  ('pre AMT_GOODS_PRICE / CNT_PAYMENT', 'mean'),\n",
    "                                  ('pre AMT_ANNUITY / AMT_CREDIT', 'mean'),                                  \n",
    "                                  ('pre DAYS_LAST_DUE_1ST_VERSION - DAYS_LAST_DUE', 'max') \n",
    "                                           ]),\n",
    "        (['NAME_CASH_LOAN_PURPOSE'], [('pre AMT_CREDIT / AMT_ANNUITY', 'mean'),\n",
    "                                  ('pre AMT_GOODS_PRICE / CNT_PAYMENT', 'mean'),\n",
    "                                  ('pre AMT_ANNUITY / AMT_CREDIT', 'mean'),                                  \n",
    "                                  ('pre DAYS_LAST_DUE_1ST_VERSION - DAYS_LAST_DUE', 'max') \n",
    "                                           ]),        \n",
    "        (['NAME_PAYMENT_TYPE'], [('pre AMT_CREDIT / AMT_ANNUITY', 'mean'),\n",
    "                                  ('pre AMT_GOODS_PRICE / CNT_PAYMENT', 'mean'),\n",
    "                                  ('pre AMT_ANNUITY / AMT_CREDIT', 'mean'),                                  \n",
    "                                  ('pre DAYS_LAST_DUE_1ST_VERSION - DAYS_LAST_DUE', 'max') \n",
    "                                           ]),        \n",
    "        (['NAME_CONTRACT_STATUS', 'NAME_CASH_LOAN_PURPOSE'], [('pre AMT_CREDIT / AMT_ANNUITY', 'mean'),\n",
    "                                  ('pre AMT_GOODS_PRICE / CNT_PAYMENT', 'mean'),\n",
    "                                  ('pre AMT_ANNUITY / AMT_CREDIT', 'mean'),                                  \n",
    "                                  ('pre DAYS_LAST_DUE_1ST_VERSION - DAYS_LAST_DUE', 'max'), \n",
    "                                  ('pre DAYS_LAST_DUE - DAYS_TERMINATION', 'max'),                                                               \n",
    "                                           ]),                \n",
    "    ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_application.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('previous_application groupby features, diff'):\n",
    "    previous_application  = make_agg_by_recipies(previous_application, PRE_AGGREGATION_RECIPIES, 'pre ')\n",
    "    previous_application  = make_agg_diff_by_recipies(previous_application, PRE_AGGREGATION_RECIPIES, 'pre ')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('previous_application features categorical'):\n",
    "    prev_app_cats = _get_categorical_features(previous_application)\n",
    "    previous_application = _get_dummies(previous_application, prev_app_cats)\n",
    "\n",
    "with timer('previous_application features mean'):\n",
    "    ## Average values for all other features in previous applications\n",
    "    prev_apps_avg = previous_application.groupby('SK_ID_CURR').mean()\n",
    "    prev_apps_avg.columns = ['pre ' + col + '_mean' for col in prev_apps_avg.columns]\n",
    "    data = data.merge(right=prev_apps_avg.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    del prev_apps_avg\n",
    "    gc.collect()\n",
    "\n",
    "with timer('previous_application features agg by self choice'):\n",
    "    num_aggregations = {\n",
    "            'AMT_ANNUITY': ['min', 'max', 'mean', 'var'],\n",
    "            'AMT_APPLICATION': ['min', 'max', 'mean', 'var'],\n",
    "            'AMT_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "            'pre AMT_APPLICATION / AMT_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "            'AMT_DOWN_PAYMENT': ['min', 'max', 'mean', 'var'],\n",
    "            'AMT_GOODS_PRICE': ['min', 'max', 'mean', 'var'],\n",
    "            'HOUR_APPR_PROCESS_START': ['min', 'max', 'mean', 'var'],\n",
    "            'RATE_DOWN_PAYMENT': ['min', 'max', 'mean', 'var'],\n",
    "            'DAYS_DECISION': ['min', 'max', 'mean', 'var'],\n",
    "            'CNT_PAYMENT': ['min', 'max', 'mean', 'var'],\n",
    "    }\n",
    "\n",
    "    cat_aggregations = {}\n",
    "\n",
    "    prev_agg = previous_application.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    prev_agg.columns = pd.Index(['pre ' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "\n",
    "with timer('previous_application features domain agg'):\n",
    "    # Approved Applications\n",
    "    approved = previous_application[previous_application['NAME_CONTRACT_STATUS'] == 'Approved']\n",
    "    approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    approved_agg.columns = pd.Index(['pre APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "    prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "    # Refused Applications\n",
    "    refused = previous_application[previous_application['NAME_CONTRACT_STATUS'] == 'Refused']\n",
    "    refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    refused_agg.columns = pd.Index(['pre REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "    prev_done = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')\n",
    "    del refused, refused_agg, approved, approved_agg\n",
    "    gc.collect()\n",
    "\n",
    "    data = data.merge(right=prev_done.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    del prev_done\n",
    "    gc.collect()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_k_previous_features(pre, periods):   \n",
    "    features = {}\n",
    "\n",
    "    for period in periods:\n",
    "        period_name = 'last_{}_'.format(period)\n",
    "        gr_period = pre[(pre['DAYS_TERMINATION'] < period)].groupby(['SK_ID_CURR'])\n",
    "        \n",
    "        features = add_features_in_group(features,gr_period, 'DAYS_LAST_DUE_1ST_VERSION', \n",
    "                                       ['sum','mean','max','min','std', 'median'],\n",
    "                                         'last_{}_'.format(period))\n",
    "        \n",
    "        features = add_features_in_group(features,gr_period, 'pre_pcb MONTHS_BALANCE_mean', \n",
    "                                       ['sum','mean','max','min','std', 'median'],\n",
    "                                         'last_{}_'.format(period))\n",
    "        features = add_features_in_group(features,gr_period ,'mer DAYS_FIRST_DUE - pre_ins DAYS_INSTALMENT_mean', \n",
    "                                     ['count','mean'],\n",
    "                                         'last_{}_'.format(period))\n",
    "        features = add_features_in_group(features,gr_period ,'pre AMT_CREDIT / AMT_ANNUITY', \n",
    "                                       ['sum','mean','max','min','std', 'median'],\n",
    "                                         'last_{}_'.format(period))\n",
    "        features = add_features_in_group(features,gr_period,'pre DAYS_LAST_DUE_1ST_VERSION - DAYS_LAST_DUE', \n",
    "                                     ['count','mean'],\n",
    "                                         'last_{}_'.format(period))        \n",
    "    \n",
    "    pd_features = pd.DataFrame(features)\n",
    "    pd_features.index.name = 'SK_ID_CURR'\n",
    "        \n",
    "    return pd_features\n",
    "  \n",
    "def add_features_in_group(features, gr_, feature_name, aggs, prefix):\n",
    "    for agg in aggs:\n",
    "        if agg == 'sum':\n",
    "            features['{}{}_sum'.format(prefix, feature_name)] = gr_[feature_name].sum()\n",
    "        elif agg == 'mean':\n",
    "            features['{}{}_mean'.format(prefix, feature_name)] = gr_[feature_name].mean()\n",
    "        elif agg == 'max':\n",
    "            features['{}{}_max'.format(prefix, feature_name)] = gr_[feature_name].max()\n",
    "        elif agg == 'min':\n",
    "            features['{}{}_min'.format(prefix, feature_name)] = gr_[feature_name].min()\n",
    "        elif agg == 'std':\n",
    "            features['{}{}_std'.format(prefix, feature_name)] = gr_[feature_name].std()\n",
    "        elif agg == 'count':\n",
    "            features['{}{}_count'.format(prefix, feature_name)] = gr_[feature_name].count()\n",
    "        elif agg == 'skew':\n",
    "            features['{}{}_skew'.format(prefix, feature_name)] = gr_[feature_name].skew()\n",
    "        elif agg == 'kurt':\n",
    "            features['{}{}_kurt'.format(prefix, feature_name)] = gr_[feature_name].kurt()\n",
    "        elif agg == 'median':\n",
    "            features['{}{}_median'.format(prefix, feature_name)] = gr_[feature_name].median()\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('previous application features period'):\n",
    "    g = last_k_previous_features(previous_application, periods=[-1, -100,-500,-1000,-1500,-2500])\n",
    "    data = data.merge(g, on='SK_ID_CURR', how='left')\n",
    "    del g\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(previous_application.DAYS_TERMINATION.fillna(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"1.2\">1.2 Feature Engineering - Bureau Data</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('bureau features'):\n",
    "\n",
    "    bureau['bur NAN num'] = bureau.isnull().sum(axis = 1).values\n",
    "    bureau_balance['bur_bal NAN num'] = bureau_balance.isnull().sum(axis = 1).values\n",
    "    \n",
    "    # Average Values for all bureau features \n",
    "    bureau_avg = bureau.groupby('SK_ID_CURR').mean()\n",
    "    bureau_avg['bur CNT'] = bureau[['SK_ID_BUREAU','SK_ID_CURR']].groupby('SK_ID_CURR').count()['SK_ID_BUREAU']\n",
    "    bureau_avg.columns = ['bur ' + f_ + '_mean' for f_ in bureau_avg.columns]\n",
    "    data = data.merge(right=bureau_avg.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    del bureau_avg\n",
    "    gc.collect()    \n",
    "    \n",
    "with timer('bureau features agg by self choice'):\n",
    "    # Bureau balance: Perform aggregations and merge with bureau.csv\n",
    "    bureau_balance['Factorized Status'], _ = pd.factorize(bureau_balance['STATUS'])\n",
    "    bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size', 'var', 'mean'],\n",
    "                       'Factorized Status':['min', 'max', 'size', 'var', 'mean']}\n",
    "    bb_agg = bureau_balance.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
    "    bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "    bureau = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "    bureau.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n",
    "    del bureau_balance, bb_agg\n",
    "    gc.collect()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('app groupby features define'):\n",
    "    BUR_AGGREGATION_RECIPIES = [\n",
    "        (['CREDIT_TYPE', 'CREDIT_ACTIVE'], [('DAYS_CREDIT', 'mean'),\n",
    "                                            ('DAYS_CREDIT_ENDDATE', 'mean'),\n",
    "                                            ('DAYS_CREDIT_UPDATE', 'mean'),\n",
    "                                            ('CREDIT_DAY_OVERDUE', 'mean'),\n",
    "                                            ('AMT_CREDIT_MAX_OVERDUE', 'mean'),\n",
    "                                            ('AMT_CREDIT_SUM', 'max'),\n",
    "                                            ('AMT_CREDIT_SUM_DEBT', 'mean'),\n",
    "                                            ('AMT_CREDIT_SUM_OVERDUE', 'mean'),\n",
    "                                            ('AMT_CREDIT_SUM_LIMIT', 'mean'),\n",
    "                                            ('AMT_ANNUITY', 'mean'),\n",
    "                                            ('CNT_CREDIT_PROLONG', 'mean'),\n",
    "                                            ('MONTHS_BALANCE_MIN', 'mean'),\n",
    "                                            ('MONTHS_BALANCE_MAX', 'mean'),\n",
    "                                            ('MONTHS_BALANCE_SIZE', 'mean') \n",
    "                                           ]),\n",
    "        (['CREDIT_TYPE', 'CREDIT_CURRENCY'], [('DAYS_CREDIT', 'mean'),\n",
    "                                            ('DAYS_CREDIT_ENDDATE', 'mean'),\n",
    "                                            ('DAYS_CREDIT_UPDATE', 'mean'),\n",
    "                                            ('CREDIT_DAY_OVERDUE', 'mean'),\n",
    "                                            ('AMT_CREDIT_MAX_OVERDUE', 'mean'),\n",
    "                                            ('AMT_CREDIT_SUM', 'max'),\n",
    "                                            ('AMT_CREDIT_SUM_DEBT', 'mean'),\n",
    "                                            ('AMT_CREDIT_SUM_OVERDUE', 'mean'),\n",
    "                                            ('AMT_CREDIT_SUM_LIMIT', 'mean'),\n",
    "                                            ('AMT_ANNUITY', 'mean'),\n",
    "                                            ('CNT_CREDIT_PROLONG', 'mean'),\n",
    "                                            ('MONTHS_BALANCE_MIN', 'mean'),\n",
    "                                            ('MONTHS_BALANCE_MAX', 'mean'),\n",
    "                                            ('MONTHS_BALANCE_SIZE', 'mean') \n",
    "                                           ]),        \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('bur groupby features, diff'):\n",
    "    bureau  = make_agg_by_recipies(bureau, BUR_AGGREGATION_RECIPIES, 'bur ')\n",
    "    bureau  = make_agg_diff_by_recipies(bureau, BUR_AGGREGATION_RECIPIES, 'bur ')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('bureau features categorical'):    \n",
    "    bureau_cats = _get_categorical_features(bureau)\n",
    "    bureau = _get_dummies(bureau, bureau_cats)\n",
    "\n",
    "with timer('bureau features mean'):    \n",
    "    # Bureau and bureau_balance numeric features\n",
    "    num_aggregations = {\n",
    "        'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "        'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "        'DAYS_CREDIT_UPDATE': ['mean', 'max'],\n",
    "        'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "        'AMT_CREDIT_MAX_OVERDUE': ['mean', 'max'],\n",
    "        'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "        'AMT_CREDIT_SUM_OVERDUE': ['mean', 'max'],\n",
    "        'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum', 'max', 'min'],\n",
    "        'AMT_ANNUITY': ['mean', 'sum', 'max', 'min'],\n",
    "        'CNT_CREDIT_PROLONG': ['mean', 'sum', 'max', 'min'],\n",
    "        'MONTHS_BALANCE_MIN': ['mean', 'sum', 'max', 'min'],\n",
    "        'MONTHS_BALANCE_MAX': ['mean', 'sum', 'max', 'min'],\n",
    "        'MONTHS_BALANCE_SIZE': ['mean', 'sum', 'max', 'min']\n",
    "    }\n",
    "\n",
    "    # Bureau and bureau_balance categorical features\n",
    "    cat_aggregations = {}\n",
    "\n",
    "    bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "    bureau_agg.columns = pd.Index(['bur_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "    \n",
    "with timer('bureau features domain agg'):\n",
    "    # Bureau: Active credits - using only numerical aggregations\n",
    "    active = bureau[bureau['CREDIT_ACTIVE'] == 'Active']\n",
    "    active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    active_agg.columns = pd.Index(['bur_ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
    "    del active, active_agg\n",
    "    gc.collect()\n",
    "\n",
    "    # Bureau: Closed credits - using only numerical aggregations\n",
    "    closed = bureau[bureau['CREDIT_ACTIVE'] == 'Closed']\n",
    "    closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "    closed_agg.columns = pd.Index(['bur_CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "    bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')\n",
    "    del closed, closed_agg, bureau\n",
    "    gc.collect()\n",
    "\n",
    "    data = data.merge(right=bureau_agg.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    del bureau_agg\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"1.3\">1.3 Feature Engineering - Previous Installments</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('installments_payments features'):\n",
    "    # nan num\n",
    "    installments_payments['ins NAN num'] = installments_payments.isnull().sum(axis = 1).values\n",
    "\n",
    "    # Percentage and difference paid in each installment (amount paid and installment value)\n",
    "    installments_payments['ins AMT_PAYMENT / AMT_INSTALMENT'] = installments_payments['AMT_PAYMENT'] / installments_payments['AMT_INSTALMENT']\n",
    "    installments_payments['ins AMT_INSTALMENT - AMT_PAYMENT'] = installments_payments['AMT_INSTALMENT'] - installments_payments['AMT_PAYMENT']\n",
    "\n",
    "    # Days past due and days before due (no negative values)\n",
    "    installments_payments['ins DAYS_ENTRY_PAYMENT - DAYS_INSTALMENT'] = installments_payments['DAYS_ENTRY_PAYMENT'] - installments_payments['DAYS_INSTALMENT']\n",
    "    installments_payments['ins DAYS_INSTALMENT - DAYS_ENTRY_PAYMENT'] = installments_payments['DAYS_INSTALMENT'] - installments_payments['DAYS_ENTRY_PAYMENT']\n",
    "    installments_payments['ins DAYS_ENTRY_PAYMENT - DAYS_INSTALMENT'] = installments_payments['ins DAYS_ENTRY_PAYMENT - DAYS_INSTALMENT'].apply(lambda x: x if x > 0 else 0)\n",
    "    installments_payments['ins DAYS_INSTALMENT - DAYS_ENTRY_PAYMENT'] = installments_payments['ins DAYS_INSTALMENT - DAYS_ENTRY_PAYMENT'].apply(lambda x: x if x > 0 else 0)\n",
    "\n",
    "    #\n",
    "    installments_payments['ins instalment_paid_late'] = (installments_payments['ins DAYS_ENTRY_PAYMENT - DAYS_INSTALMENT'] > 0).astype(int)\n",
    "    installments_payments['ins instalment_paid_over'] = (installments_payments['ins AMT_INSTALMENT - AMT_PAYMENT'] > 0).astype(int)\n",
    "\n",
    "with timer('installments_payments features mean'):   \n",
    "    ## Average values for all other variables in installments payments\n",
    "    avg_inst = installments_payments.groupby('SK_ID_CURR').mean()\n",
    "    avg_inst.columns = ['ins ' + f_ + '_mean' for f_ in avg_inst.columns]\n",
    "    data = data.merge(right=avg_inst.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    del avg_inst\n",
    "    gc.collect()\n",
    "\n",
    "    ## count the number of previous installments\n",
    "    cnt_inst = installments_payments[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "    installments_payments['ins_SK_ID_PREV_CNT'] = installments_payments['SK_ID_CURR'].map(cnt_inst['SK_ID_PREV'])\n",
    "    installments_payments.drop(['SK_ID_PREV'], axis = 1, inplace = True)\n",
    "\n",
    "with timer('installments_payments features agg by self choice'):\n",
    "    aggregations = {\n",
    "         'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "         'ins DAYS_ENTRY_PAYMENT - DAYS_INSTALMENT': ['max', 'sum','min','std','var'],\n",
    "         'ins DAYS_INSTALMENT - DAYS_ENTRY_PAYMENT': ['max', 'sum','min','std','var'],\n",
    "         'ins AMT_PAYMENT / AMT_INSTALMENT': [ 'max', 'min','std','var'],\n",
    "         'ins AMT_INSTALMENT - AMT_PAYMENT': [ 'max', 'min','std','var'],\n",
    "         'AMT_INSTALMENT': ['max', 'sum','min','std','var'],\n",
    "         'AMT_PAYMENT': ['min', 'max', 'sum','std','var'],\n",
    "         'DAYS_ENTRY_PAYMENT': ['max', 'sum','std','var'],\n",
    "         'ins instalment_paid_late': ['sum','mean','max','min','std'],   \n",
    "         'ins instalment_paid_over': ['sum','mean','max','min','std'],\n",
    "    }\n",
    "\n",
    "    ins_agg = installments_payments.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    ins_agg.columns = pd.Index(['ins ' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "\n",
    "    # Count installments accounts\n",
    "    ins_agg['INSTAL_COUNT'] = installments_payments.groupby('SK_ID_CURR').size()\n",
    "    #del installments_payments\n",
    "    gc.collect()\n",
    "\n",
    "    data = data.merge(right=ins_agg.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    del ins_agg\n",
    "    gc.collect()\n",
    "    \n",
    "#with timer('installments_payments features domain agg'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_k_installment_features(ins, periods):   \n",
    "    features = {}\n",
    "\n",
    "    for period in periods:\n",
    "        period_name = 'last_{}_'.format(period)\n",
    "        gr_period = ins[(ins['DAYS_INSTALMENT'] < period)].groupby(['SK_ID_CURR'])\n",
    "        \n",
    "        features = add_features_in_group(features,gr_period, 'NUM_INSTALMENT_VERSION', \n",
    "                                       ['sum','mean','max','min','std', 'median'],\n",
    "                                         'last_{}_'.format(period))\n",
    "        \n",
    "        features = add_features_in_group(features,gr_period, 'ins DAYS_ENTRY_PAYMENT - DAYS_INSTALMENT', \n",
    "                                       ['sum','mean','max','min','std', 'median'],\n",
    "                                         'last_{}_'.format(period))\n",
    "        features = add_features_in_group(features,gr_period ,'ins instalment_paid_late', \n",
    "                                     ['count','mean'],\n",
    "                                         'last_{}_'.format(period))\n",
    "        features = add_features_in_group(features,gr_period ,'ins AMT_INSTALMENT - AMT_PAYMENT', \n",
    "                                       ['sum','mean','max','min','std', 'median'],\n",
    "                                         'last_{}_'.format(period))\n",
    "        features = add_features_in_group(features,gr_period,'ins instalment_paid_over', \n",
    "                                     ['count','mean'],\n",
    "                                         'last_{}_'.format(period))        \n",
    "    \n",
    "    pd_features = pd.DataFrame(features)\n",
    "    pd_features.index.name = 'SK_ID_CURR'\n",
    "        \n",
    "    return pd_features\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('installments_payments features period'):\n",
    "    g = last_k_installment_features(installments_payments, periods=[-1, -100,-500,-1000,-1500,-2500])\n",
    "    data = data.merge(g, on='SK_ID_CURR', how='left')\n",
    "    del g\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(installments_payments['DAYS_INSTALMENT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"1.4\">1.4 Feature Engineering - Pos Cash Balance</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('pcb features'):\n",
    "    pcb['pcb NAN num'] = pcb.isnull().sum(axis = 1).values\n",
    "    pcb['pcb cash_paid_late'] = (pcb['SK_DPD'] > 0).astype(int)\n",
    "    pcb['pcb cash_paid_late_with_tolerance'] = (pcb['SK_DPD_DEF'] > 0).astype(int)\n",
    "\n",
    "    ### count the number of pos cash for a given ID\n",
    "    pcb_count = pcb[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "    pcb['pcb_SK_ID_PREV_CNT'] = pcb['SK_ID_CURR'].map(pcb_count['SK_ID_PREV'])\n",
    "\n",
    "with timer('pcb features categorical'):    \n",
    "    pcb_cats = _get_categorical_features(pcb)\n",
    "    pcb = _get_dummies(pcb, pcb_cats)\n",
    "    \n",
    "with timer('pcb features mean'):\n",
    "    ## Average Values for all other variables in pos cash\n",
    "    pcb_avg = pcb.groupby('SK_ID_CURR').mean()\n",
    "    data = data.merge(right=pcb_avg.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    del pcb_avg\n",
    "    gc.collect()\n",
    "\n",
    "with timer('pcb features agg by self choice'):\n",
    "    pos_cash_sorted = pcb.sort_values(['SK_ID_CURR', 'MONTHS_BALANCE'])\n",
    "    group_object = pos_cash_sorted.groupby('SK_ID_CURR')['CNT_INSTALMENT_FUTURE'].last().reset_index()\n",
    "    group_object.rename(index=str, columns={'CNT_INSTALMENT_FUTURE': 'pcb cash_remaining_installments'}, inplace=True)\n",
    "    data = data.merge(group_object, on=['SK_ID_CURR'], how='left')\n",
    "\n",
    "with timer('pcb features domain agg'):\n",
    "    pcb['is_contract_status_completed'] = pcb['NAME_CONTRACT_STATUS'] == 'Completed'\n",
    "    group_object = pcb.groupby(['SK_ID_CURR'])['is_contract_status_completed'].sum().reset_index()\n",
    "    group_object.rename(index=str,\n",
    "                        columns={'is_contract_status_completed': 'pcb cash_completed_contracts'},\n",
    "                        inplace=True)\n",
    "    data = data.merge(group_object, on=['SK_ID_CURR'], how='left')\n",
    "    del group_object\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_k_pcb_features(dt, periods):\n",
    "    \n",
    "    features = {}\n",
    "    for period in periods:\n",
    "        period_name = 'last_{}_'.format(period)\n",
    "        gr_period = pcb[(pcb['MONTHS_BALANCE'] < period)].groupby(['SK_ID_CURR'])\n",
    "            \n",
    "        features = add_features_in_group(features, gr_period, 'pcb cash_paid_late',\n",
    "                                             ['count', 'mean'],\n",
    "                                             period_name)\n",
    "        features = add_features_in_group(features, gr_period, 'pcb cash_paid_late_with_tolerance',\n",
    "                                             ['count', 'mean'],\n",
    "                                             period_name)\n",
    "        features = add_features_in_group(features, gr_period, 'SK_DPD',\n",
    "                                             ['sum', 'mean', 'max', 'min', 'median'],\n",
    "                                             period_name)\n",
    "        features = add_features_in_group(features, gr_period, 'SK_DPD_DEF',\n",
    "                                             ['sum', 'mean', 'max', 'min','median'],\n",
    "                                             period_name)\n",
    "\n",
    "    pd_features = pd.DataFrame(features)\n",
    "    pd_features.index.name = 'SK_ID_CURR'\n",
    "    return pd_features\n",
    "\n",
    "def last_loan_features(gr):\n",
    "    gr_ = gr.copy()\n",
    "    gr_.sort_values(['MONTHS_BALANCE'], ascending=False, inplace=True)\n",
    "    last_installment_id = gr_['SK_ID_PREV'].iloc[0]\n",
    "    gr_ = gr_[gr_['SK_ID_PREV'] == last_installment_id]  \n",
    "    gr_ = gr_.groupby(['SK_ID_CURR'])\n",
    "        \n",
    "    features={}\n",
    "    features = add_features_in_group(features, gr_, 'pcb cash_paid_late',\n",
    "                                         ['count', 'sum', 'mean'],\n",
    "                                         'last_loan_')\n",
    "    features = add_features_in_group(features, gr_, 'pcb cash_paid_late_with_tolerance',\n",
    "                                         ['sum', 'mean'],\n",
    "                                         'last_loan_')\n",
    "    features = add_features_in_group(features, gr_, 'SK_DPD',\n",
    "                                         ['sum', 'mean', 'max', 'min', 'std'],\n",
    "                                         'last_loan_')\n",
    "    features = add_features_in_group(features, gr_, 'SK_DPD_DEF',\n",
    "                                         ['sum', 'mean', 'max', 'min', 'std'],\n",
    "                                         'last_loan_')\n",
    "    pd_features = pd.DataFrame(features)\n",
    "    pd_features.index.name = 'SK_ID_CURR'   \n",
    "    \n",
    "    return pd_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('pcb features period'):\n",
    "    features = pd.DataFrame({'SK_ID_CURR': pcb['SK_ID_CURR'].unique()})\n",
    "    g = last_k_pcb_features(pcb, periods=[-1, -6, -10, -30, -60, -80])\n",
    "    features = features.merge(g, on='SK_ID_CURR', how='left')\n",
    "    data = data.merge(features, on='SK_ID_CURR', how='left')\n",
    "    \n",
    "with timer('pcb last_loan_features'):    \n",
    "    g = last_loan_features(pcb)\n",
    "    data = data.merge(g, on='SK_ID_CURR', how='left')\n",
    "    del g\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(pcb['MONTHS_BALANCE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('pcb features agg by self choice'):\n",
    "    ### count the number of pos cash for a given ID\n",
    "    pcb_count = pcb[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "    pcb['pcb_SK_ID_PREV_CNT'] = pcb['SK_ID_CURR'].map(pcb_count['SK_ID_PREV'])\n",
    "    pcb.drop(['SK_ID_PREV'], axis = 1, inplace = True)\n",
    "\n",
    "    # Features\n",
    "    aggregations = {\n",
    "         'MONTHS_BALANCE': ['mean', 'max', 'min', 'sum', 'var', 'size'],\n",
    "         'CNT_INSTALMENT' : ['mean', 'max'],\n",
    "         'CNT_INSTALMENT_FUTURE' : ['mean', 'max'],\n",
    "         'SK_DPD': ['mean', 'max', 'min', 'sum', 'var'],\n",
    "         'SK_DPD_DEF': ['mean', 'max', 'min', 'sum', 'var']\n",
    "    }\n",
    "    pos_agg = pcb.groupby('SK_ID_CURR').agg(aggregations)\n",
    "    pos_agg.columns = pd.Index(['pcb ' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "\n",
    "    # Count pos cash accounts\n",
    "    pos_agg['POS_COUNT'] = pcb.groupby('SK_ID_CURR').size()\n",
    "    del pcb\n",
    "    gc.collect()\n",
    "\n",
    "    data = data.merge(right=pos_agg.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    del pos_agg\n",
    "    gc.collect()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"1.5\">1.5 Feature Engineering - Credit Card Balance </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('credit_card_balance features handcraft'):\n",
    "    # No of Loans per customer \n",
    "    grp = credit_card_balance.groupby(by = ['SK_ID_CURR'])['SK_ID_PREV'].nunique().reset_index().rename(index = str, columns = {'SK_ID_PREV': 'cre NO_LOANS'})\n",
    "    credit_card_balance = credit_card_balance.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "    del grp \n",
    "    gc.collect()\n",
    "\n",
    "    # No of Installments paid per Loan per Customer \n",
    "    grp = credit_card_balance.groupby(by = ['SK_ID_CURR', 'SK_ID_PREV'])['CNT_INSTALMENT_MATURE_CUM'].max().reset_index().rename(index = str, columns = {'CNT_INSTALMENT_MATURE_CUM': 'cre NO_INSTALMENTS'})\n",
    "    grp1 = grp.groupby(by = ['SK_ID_CURR'])['cre NO_INSTALMENTS'].sum().reset_index().rename(index = str, columns = {'cre NO_INSTALMENTS': 'cre TOTAL_INSTALMENTS'})\n",
    "    credit_card_balance = credit_card_balance.merge(grp1, on = ['SK_ID_CURR'], how = 'left')\n",
    "    del grp, grp1\n",
    "    gc.collect()\n",
    "\n",
    "    # Average Number of installments paid per loan \n",
    "    credit_card_balance['cre INSTALLMENTS_PER_LOAN'] = (credit_card_balance['cre TOTAL_INSTALMENTS']/credit_card_balance['cre NO_LOANS']).astype('uint32')\n",
    "    del credit_card_balance['cre TOTAL_INSTALMENTS']\n",
    "    del credit_card_balance['cre NO_LOANS']\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('credit_card_balance features handcraft'):\n",
    "    credit_card_balance['AMT_CREDIT_LIMIT_ACTUAL1'] = credit_card_balance['AMT_CREDIT_LIMIT_ACTUAL']\n",
    "\n",
    "    def f(x1, x2):\n",
    "\n",
    "        balance = x1.max()\n",
    "        limit = x2.max()\n",
    "\n",
    "        return (balance/limit)\n",
    "\n",
    "    # Calculate the ratio of Amount Balance to Credit Limit - CREDIT LOAD OF CUSTOMER \n",
    "    # This is done for each Credit limit value per loan per Customer \n",
    "\n",
    "    grp = credit_card_balance.groupby(by = ['SK_ID_CURR', 'SK_ID_PREV', 'AMT_CREDIT_LIMIT_ACTUAL']).apply(lambda x: f(x.AMT_BALANCE, x.AMT_CREDIT_LIMIT_ACTUAL1)).reset_index().rename(index = str, columns = {0: 'CREDIT_LOAD1'})\n",
    "    del credit_card_balance['AMT_CREDIT_LIMIT_ACTUAL1']\n",
    "    gc.collect()\n",
    "\n",
    "    # We now calculate the mean Credit load of All Loan transactions of Customer \n",
    "    grp1 = grp.groupby(by = ['SK_ID_CURR'])['CREDIT_LOAD1'].mean().reset_index().rename(index = str, columns = {'CREDIT_LOAD1': 'cre CREDIT_LOAD'})\n",
    "    print(grp1.dtypes)\n",
    "\n",
    "    credit_card_balance = credit_card_balance.merge(grp1, on = ['SK_ID_CURR'], how = 'left')\n",
    "    del grp, grp1\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('credit_card_balance features handcraft'):\n",
    "    def f(DPD):\n",
    "\n",
    "        # DPD is a series of values of SK_DPD for each of the groupby combination \n",
    "        # We convert it to a list to get the number of SK_DPD values NOT EQUALS ZERO\n",
    "        x = DPD.tolist()\n",
    "        c = 0\n",
    "        for i,j in enumerate(x):\n",
    "            if j != 0:\n",
    "                c += 1\n",
    "\n",
    "        return c \n",
    "\n",
    "    grp = credit_card_balance.groupby(by = ['SK_ID_CURR', 'SK_ID_PREV']).apply(lambda x: f(x.SK_DPD)).reset_index().rename(index = str, columns = {0: 'NO_DPD'})\n",
    "    grp1 = grp.groupby(by = ['SK_ID_CURR'])['NO_DPD'].mean().reset_index().rename(index = str, columns = {'NO_DPD' : 'cre DPD_COUNT'})\n",
    "\n",
    "    credit_card_balance = credit_card_balance.merge(grp1, on = ['SK_ID_CURR'], how = 'left')\n",
    "    del grp1\n",
    "    del grp \n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('credit_card_balance features handcraft'):\n",
    "    grp = credit_card_balance.groupby(by= ['SK_ID_CURR'])['SK_DPD'].mean().reset_index().rename(index = str, columns = {'SK_DPD': 'cre AVG_DPD'})\n",
    "    credit_card_balance = credit_card_balance.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "    del grp \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('credit_card_balance features handcraft'):\n",
    "    def f(min_pay, total_pay):\n",
    "\n",
    "        M = min_pay.tolist()\n",
    "        T = total_pay.tolist()\n",
    "        P = len(M)\n",
    "        c = 0 \n",
    "        # Find the count of transactions when Payment made is less than Minimum Payment \n",
    "        for i in range(len(M)):\n",
    "            if T[i] < M[i]:\n",
    "                c += 1  \n",
    "        return (100*c)/P\n",
    "\n",
    "    grp = credit_card_balance.groupby(by = ['SK_ID_CURR']).apply(lambda x: f(x.AMT_INST_MIN_REGULARITY, x.AMT_PAYMENT_CURRENT)).reset_index().rename(index = str, columns = { 0 : 'cre PERCENTAGE_MISSED_PAYMENTS'})\n",
    "    credit_card_balance = credit_card_balance.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "    del grp \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('credit_card_balance features handcraft'):\n",
    "    grp = credit_card_balance.groupby(by = ['SK_ID_CURR'])['AMT_DRAWINGS_ATM_CURRENT'].sum().reset_index().rename(index = str, columns = {'AMT_DRAWINGS_ATM_CURRENT' : 'cre DRAWINGS_ATM'})\n",
    "    credit_card_balance = credit_card_balance.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "    del grp\n",
    "    gc.collect()\n",
    "\n",
    "    grp = credit_card_balance.groupby(by = ['SK_ID_CURR'])['AMT_DRAWINGS_CURRENT'].sum().reset_index().rename(index = str, columns = {'AMT_DRAWINGS_CURRENT' : 'cre DRAWINGS_TOTAL'})\n",
    "    credit_card_balance = credit_card_balance.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "    del grp\n",
    "    gc.collect()\n",
    "\n",
    "    credit_card_balance['cre CASH_CARD_RATIO1'] = (credit_card_balance['cre DRAWINGS_ATM']/credit_card_balance['cre DRAWINGS_TOTAL'])*100\n",
    "    del credit_card_balance['cre DRAWINGS_ATM']\n",
    "    del credit_card_balance['cre DRAWINGS_TOTAL']\n",
    "    gc.collect()\n",
    "\n",
    "    grp = credit_card_balance.groupby(by = ['SK_ID_CURR'])['cre CASH_CARD_RATIO1'].mean().reset_index().rename(index = str, columns ={ 'cre CASH_CARD_RATIO1' : 'cre CASH_CARD_RATIO'})\n",
    "    credit_card_balance = credit_card_balance.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "    del grp \n",
    "    gc.collect()\n",
    "\n",
    "    del credit_card_balance['cre CASH_CARD_RATIO1']\n",
    "    gc.collect()\n",
    "    \n",
    "    grp = credit_card_balance.groupby(by = ['SK_ID_CURR'])['AMT_DRAWINGS_CURRENT'].sum().reset_index().rename(index = str, columns = {'AMT_DRAWINGS_CURRENT' : 'cre TOTAL_DRAWINGS'})\n",
    "    credit_card_balance = credit_card_balance.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "    del grp\n",
    "    gc.collect()\n",
    "\n",
    "    grp = credit_card_balance.groupby(by = ['SK_ID_CURR'])['CNT_DRAWINGS_CURRENT'].sum().reset_index().rename(index = str, columns = {'CNT_DRAWINGS_CURRENT' : 'cre NO_DRAWINGS'})\n",
    "    credit_card_balance = credit_card_balance.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "    del grp\n",
    "    gc.collect()\n",
    "\n",
    "    credit_card_balance['cre DRAWINGS_RATIO1'] = (credit_card_balance['cre TOTAL_DRAWINGS']/credit_card_balance['cre NO_DRAWINGS'])*100\n",
    "    del credit_card_balance['cre TOTAL_DRAWINGS']\n",
    "    del credit_card_balance['cre NO_DRAWINGS']\n",
    "    gc.collect()\n",
    "\n",
    "    grp = credit_card_balance.groupby(by = ['SK_ID_CURR'])['cre DRAWINGS_RATIO1'].mean().reset_index().rename(index = str, columns ={ 'cre DRAWINGS_RATIO1' : 'cre DRAWINGS_RATIO'})\n",
    "    credit_card_balance = credit_card_balance.merge(grp, on = ['SK_ID_CURR'], how = 'left')\n",
    "    del grp \n",
    "    gc.collect()\n",
    "\n",
    "    del credit_card_balance['cre DRAWINGS_RATIO1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with timer('credit_card_balance features'):\n",
    "    credit_card_balance['cre NAN num'] = credit_card_balance.isnull().sum(axis = 1).values\n",
    "\n",
    "with timer('credit_card_balance features categorical'):\n",
    "    ccbal_cats = _get_categorical_features(credit_card_balance)\n",
    "    credit_card_balance = _get_dummies(credit_card_balance, ccbal_cats)    \n",
    "    \n",
    "with timer('credit_card_balance features means'):\n",
    "    ### average of all other columns \n",
    "    avg_cc_bal = credit_card_balance.groupby('SK_ID_CURR').mean()\n",
    "    avg_cc_bal.columns = ['cc_bal_' + f_ + '_mean' for f_ in avg_cc_bal.columns]\n",
    "    data = data.merge(right=avg_cc_bal.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    del avg_cc_bal\n",
    "    gc.collect()\n",
    "\n",
    "with timer('credit_card_balance features agg'):  \n",
    "    ### count the number of previous applications for a given ID\n",
    "    nb_prevs = credit_card_balance[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "    credit_card_balance['cre_SK_ID_PREV_CNT'] = credit_card_balance['SK_ID_CURR'].map(nb_prevs['SK_ID_PREV'])\n",
    "    credit_card_balance.drop(['SK_ID_PREV'], axis=1, inplace=True)\n",
    "\n",
    "    # General aggregations\n",
    "    cc_agg = credit_card_balance.groupby('SK_ID_CURR').agg([ 'max', 'sum', 'var'])\n",
    "    cc_agg.columns = pd.Index(['cre_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "    # Count credit card lines\n",
    "    cc_agg['CC_COUNT'] = credit_card_balance.groupby('SK_ID_CURR').size()\n",
    "    data = data.merge(right=cc_agg.reset_index(), how='left', on='SK_ID_CURR')\n",
    "    del cc_agg, credit_card_balance\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"1.7\">1.7 Feature Engineering - PolyFeature </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer('app features polyfeature'):\n",
    "    # Make a new dataframe for polynomial features\n",
    "    poly_features = data[['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']]\n",
    "\n",
    "    # imputer for handling missing values\n",
    "    from sklearn.preprocessing import Imputer\n",
    "    imputer = Imputer(strategy = 'median')\n",
    "\n",
    "    # Need to impute missing values\n",
    "    poly_features = imputer.fit_transform(poly_features)\n",
    "\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "    # Create the polynomial object with specified degree\n",
    "    poly_transformer = PolynomialFeatures(degree = 3)\n",
    "\n",
    "    # Train the polynomial features\n",
    "    poly_transformer.fit(poly_features)\n",
    "\n",
    "    # Transform the features\n",
    "    poly_features = poly_transformer.transform(poly_features)\n",
    "    print('Polynomial Features shape: ', poly_features.shape)\n",
    "\n",
    "    # Create a dataframe of the features \n",
    "    pd_poly_features = pd.DataFrame(poly_features, \n",
    "                                 columns = poly_transformer.get_feature_names(['POLY_EXT_SOURCE_1', 'POLY_EXT_SOURCE_2', 'POLY_EXT_SOURCE_3', 'POLY_DAYS_BIRTH']))\n",
    "    pd_poly_features = pd_poly_features.drop(columns =['1', 'POLY_EXT_SOURCE_1', 'POLY_EXT_SOURCE_2', 'POLY_EXT_SOURCE_3', 'POLY_DAYS_BIRTH'])\n",
    "    data_reset = data.reset_index()\n",
    "    pd_poly_features['SK_ID_CURR'] = data_reset['SK_ID_CURR'] \n",
    "    data = data.merge(pd_poly_features, on = 'SK_ID_CURR', how = 'left')\n",
    "    del pd_poly_features\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"0.2\">0.2 Prepare - Categorical Data Processing</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"2.0\">2.0 Prepare Final Train and Test data</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_importancs_limits = pd.read_csv('../output/feature_importances_17_5kfold.csv')\n",
    "pd_importancs_limits = pd_importancs_limits.sort_values('score', ascending=False)\n",
    "pd_importancs_limits = pd_importancs_limits.tail(data.shape[1] - 1200)\n",
    "\n",
    "ignore_features = [val for val in pd_importancs_limits['features']]\n",
    "#ignore_features = []\n",
    "ignore_features.append('SK_ID_CURR')\n",
    "ignore_features.append('is_train')\n",
    "ignore_features.append('is_test')\n",
    "\n",
    "\n",
    "relevant_features = [col for col in data.columns if col not in ignore_features]\n",
    "trainX = data[data['is_train'] == 1][relevant_features]\n",
    "testX = data[data['is_test'] == 1][relevant_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_importancs_limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"2.1\">2.1 StratifiedKFold, GridSearch</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "max_score = -100\n",
    "max_params = None\n",
    "\n",
    "all_params = {'task': ['train'], 'boosting_type': ['gbdt'], 'objective': ['binary'], 'metric': ['auc'], \n",
    "          'learning_rate': [0.01], 'num_leaves': [32, 64, 100], 'num_iteration': [5000], 'verbose': [0] ,\n",
    "          'colsample_bytree':[0.8], 'subsample':[0.9], 'max_depth':[5,7,8], 'reg_alpha':[0.1], 'reg_lambda':[0.1, 2.6900], \n",
    "          'min_split_gain':[0.01], 'min_child_weight':[1, 1.3459]}\n",
    "\n",
    "#all_params = {'task': ['train'], 'boosting_type': ['gbdt'], 'objective': ['binary'], 'metric': ['auc'], \n",
    "#          'learning_rate': [0.01], 'num_leaves': [64], 'num_iteration': [5000], 'verbose': [0] ,\n",
    "#          'colsample_bytree':[0.8], 'subsample':[0.9], 'max_depth':[8], 'reg_alpha':[0.1], 'reg_lambda':[2.6900], \n",
    "#          'min_split_gain':[0.01], 'min_child_weight':[1.3459]}\n",
    "\n",
    "\n",
    "list_auc_score = []\n",
    "list_preds = []\n",
    "\n",
    "for params in tqdm(list(ParameterGrid(all_params))):\n",
    "    for train_idx, valid_idx in cv.split(trainX, Y):\n",
    "        trn_x = trainX.iloc[train_idx, :]\n",
    "        val_x = trainX.iloc[valid_idx, :]\n",
    "    \n",
    "        trn_y = Y[train_idx]\n",
    "        val_y = Y[valid_idx]\n",
    "    \n",
    "        #lgb_train = lgb.Dataset(data=trn_x, label=trn_y)\n",
    "        #lgb_eval = lgb.Dataset(data=val_x, label=val_y)\n",
    "        #model = lgb.train(params, lgb_train,  valid_sets=lgb_eval, early_stopping_rounds=150, verbose_eval=200)\n",
    "        #preds_val = model.predict(val_x)\n",
    "        #preds = model.predict(testX)       \n",
    "        \n",
    "        clf = lgb.sklearn.LGBMClassifier(**params)\n",
    "        clf.fit(trn_x,\n",
    "                    trn_y,\n",
    "                    eval_set=[(val_x, val_y)],\n",
    "                    early_stopping_rounds=150,\n",
    "                    eval_metric='auc'\n",
    "                )        \n",
    "        preds_val = clf.predict_proba(val_x, num_iteration = clf.best_iteration_)[:, 1]\n",
    "        preds = clf.predict_proba(testX, num_iteration=clf.best_iteration_)[:, 1]\n",
    "        \n",
    "        auc = roc_auc_score(val_y, preds_val)\n",
    "        list_auc_score.append(auc)\n",
    "        list_preds.append(preds)\n",
    "        \n",
    "        if (max_score < auc):\n",
    "            max_score = auc\n",
    "            max_params = params\n",
    "    \n",
    "sc_auc_score = np.mean(list_auc_score)\n",
    "print(sc_auc_score, max_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id=\"4.1\">4.1 Feature Importance </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lgb.plot_importance(clf, figsize=(12, 25), max_num_features=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <a id=\"5.1\">5.1 Predict</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.mean(list_preds, axis=0)\n",
    "\n",
    "#preds = None\n",
    "\n",
    "    \n",
    "sub_lgb = pd.DataFrame()\n",
    "sub_lgb['SK_ID_CURR'] = test_id\n",
    "sub_lgb['TARGET'] = preds\n",
    "sub_lgb.to_csv(\"../output/18_all_5kfold_-1250.csv\", index=False)\n",
    "sub_lgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('18 plus features')\n",
    "print(sc_auc_score, ',' ,max_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('result: ???')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_list = []\n",
    "\n",
    "# 特徴量の表示\n",
    "for i in range(0, clf.feature_importances_.size):\n",
    "    index = clf.feature_importances_[i]\n",
    "    feature_importances_list.append([trn_x.columns[i], clf.feature_importances_[i]])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#18 plus features top 200\n",
    "#0.7893474119311094 , 0.7915435036428924"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18 plus features top 1200\n",
    "#0.7924808392168339 , 0.7953805830547993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#18 plus features 1000\n",
    "#0.7923640219564716 , 0.7948419914693372\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18 plus features 1350\n",
    "# 0.7925050694030311 , 0.7949374934551233\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#18 plus features 1250\n",
    "#0.7925303411084231 , 0.7948696075314758\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_importancs = pd.DataFrame(feature_importances_list)\n",
    "pd_importancs.columns = ['features', 'score']\n",
    "pd_importancs.sort_values('score', ascending=False).to_csv('../output/feature_importances_17_5kfold.csv', index=False)\n",
    "pd_importancs.sort_values('score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
